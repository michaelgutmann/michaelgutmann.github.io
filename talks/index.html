<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Michael U. Gutmann | Talks</title>
  <meta name="description" content="Research homepage of Michael U. Gutmann
">

<!--  <link rel="shortcut icon" href="https://michaelgutmann.github.io/assets/img/favicon.ico"> -->

<link rel="stylesheet" href="https://michaelgutmann.github.io/assets/css/main.css">
  <link rel="canonical" href="https://michaelgutmann.github.io/talks/">

  <!-- added roboto font family -->
  <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
</head>


  <body>

    <header class="site-header">
  <div class="wrapper">
  
    <span class="site-title">
      <!-- About -->
        
      
      <strong>Michael</strong> U. Gutmann
      
    </span>
    
    <nav class="site-nav">
      <a class="page-link" href="https://michaelgutmann.github.io/">home</a>
      
      
      
      
      
      <a class="page-link" href="https://michaelgutmann.github.io/publications/">publications</a> 
      
      
      
      <a class="page-link" href="https://michaelgutmann.github.io/talks/">talks</a> 
      
      
      
      <a class="page-link" href="https://michaelgutmann.github.io/code/">code</a> 
      
      
      
      <a class="page-link" href="https://michaelgutmann.github.io/teaching/">teaching</a> 
      
      
      
      <a class="page-link" href="https://michaelgutmann.github.io/contact/">contact</a> 
      
      
      
      
      
      
    </nav>
    
  </div>
</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    
    <h1 class="post-title">Talks and Presentations</h1>
    
    <h5 class="post-description"></h5>
  </header>

  <article class="post-content Talks clearfix">
    <ol class="bibliography"><li>


<span class="title">Modelling the Model for Approximate Bayesian Computation</span>
<span class="periodical"> <i> BIRS Workshop on Validating and Expanding Approximate Bayesian Computation Methods </i> </span>
<span class="periodical">Banff International Research Station, Banff, Alberta, Canada, Feb 2017</span>
<div id="Gutmann-2017-02-20">
  <span class="links">
    
    [<a href="https://michaelgutmann.github.io/assets/slides/Gutmann-2017-02-20.pdf" target="_blank">slides</a>]
    
    
    
    [<a href="http://www.birs.ca/events/2017/5-day-workshops/17w5025" target="_blank">url</a>]
    
   
  </span>
    <!-- Hidden abstract block -->
    
    
</div>
  

</li>
<li>


<span class="title">Likelihood-Free Inference: An Introduction to My Research</span>
<span class="periodical"> <i> NQIT Seminar </i> </span>
<span class="periodical">Edinburgh, UK, Apr 2017</span>
<div id="Gutmann-2017-04-21">
  <span class="links">
    
    [<a href="https://michaelgutmann.github.io/assets/slides/Gutmann-2017-04-21.pdf" target="_blank">slides</a>]
    
    
    
   
  </span>
    <!-- Hidden abstract block -->
    
    
</div>
  

</li>
<li>


<span class="title">Bayesian Inference by Density Ratio Estimation</span>
<span class="periodical"> <i> Workshop in Inverse Problems and Data Science </i> </span>
<span class="periodical">Edinburgh, UK, May 2017</span>
<div id="Gutmann-2017-05-09">
  <span class="links">
    
    [<a href="https://michaelgutmann.github.io/assets/slides/Gutmann-2017-05-09.pdf" target="_blank">slides</a>]
    
    
    [<a class="abstract">abs</a>]
    
    
    [<a href="https://www.turing.ac.uk/events/inverse-problems-data-science/" target="_blank">url</a>]
    
   
  </span>
    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>This talk is about Bayesian inference when the likelihood function cannot be computed but data can be generated from the model. The model’s data generating process is allowed to be arbitrarily complex. Exact solutions are then not possible. But by re-formulating the original problem as a problem of estimating the ratio between two probability density functions, I show how e.g. logistic regression can be used to obtain approximate solutions. The proposed inference framework is illustrated on stochastic nonlinear dynamical models.</p>
    </span>
    
    
</div>
  

</li>
<li>


<span class="title">Bayesian Inference by Density Ratio Estimation</span>
<span class="periodical"> <i> Dept of Computer Science, University of Oxford </i> </span>
<span class="periodical">Oxford, UK, Jun 2017</span>
<div id="Gutmann-2017-06-20">
  <span class="links">
    
    [<a href="https://michaelgutmann.github.io/assets/slides/Gutmann-2017-06-20.pdf" target="_blank">slides</a>]
    
    
    [<a class="abstract">abs</a>]
    
    
   
  </span>
    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>This talk is about Bayesian inference when the likelihood function cannot be computed but data can be generated from the model. The model’s data generating process is allowed to be arbitrarily complex. Exact solutions are then not possible. But by re-formulating the original problem as a problem of estimating the ratio between two probability density functions, I show how e.g. logistic regression can be used to obtain approximate solutions. The proposed inference framework is illustrated on stochastic nonlinear dynamical models.</p>
    </span>
    
    
</div>
  

</li>
<li>


<span class="title">Efficient Statistical Inference for Intractable Models</span>
<span class="periodical"> <i> (industry engagement) </i> </span>
<span class="periodical">Edinburgh, UK, Aug 2017</span>
<div id="Gutmann-2017-08-31">
  <span class="links">
    
    [<a href="https://michaelgutmann.github.io/assets/slides/Gutmann-2017-08-31.pdf" target="_blank">slides</a>]
    
    
    
   
  </span>
    <!-- Hidden abstract block -->
    
    
</div>
  

</li>
<li>


<span class="title">A Short Introduction to the Lasso Methodology</span>
<span class="periodical"> <i> Research group in Statistics and Biostatistics, Department of Mathematics, University of Oslo </i> </span>
<span class="periodical">Oslo, Norway, Mar 2016</span>
<div id="Gutmann-2016-03-09">
  <span class="links">
    
    [<a href="https://michaelgutmann.github.io/assets/slides/Gutmann-2016-03-09.pdf" target="_blank">slides</a>]
    
    
    
    [<a href="http://www.mn.uio.no/math/english/research/groups/statistics-biostatistics/" target="_blank">url</a>]
    
   
  </span>
    <!-- Hidden abstract block -->
    
    
</div>
  

</li>
<li>


<span class="title">Noise-Contrastive Estimation and its Generalizations</span>
<span class="periodical"> <i> CRiSM Workshop: Estimating Constants </i> </span>
<span class="periodical">Department of Statistics, University of Warwick, Coventry, UK, Apr 2016</span>
<div id="Gutmann-2016-04-21">
  <span class="links">
    
    [<a href="https://michaelgutmann.github.io/assets/slides/Gutmann-2016-04-21.pdf" target="_blank">slides</a>]
    
    
    [<a class="abstract">abs</a>]
    
    
    [<a href="https://www2.warwick.ac.uk/fac/sci/statistics/crism/workshops/estimatingconstants/" target="_blank">url</a>]
    
   
  </span>
    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Parametric statistical models are often not properly normalized, that is, they do not integrate to unity. While unnormalized models can, in principle, be normalized by dividing them by their integral, the cost of computing the integral is generally prohibitively large. This is an issue because without normalization, the likelihood function is not available for performing inference. I present a method called "noise-contrastive estimation" where unnormalized models are estimated by solving a classification problem. I explain some of its properties and applications, and show that it is part of a general estimation framework based on the SBregman divergence.</p>
    </span>
    
    
</div>
  

</li>
<li>


<span class="title">Tutorial on Approximate Bayesian Computation</span>
<span class="periodical"> <i> ABCruise </i> </span>
<span class="periodical">Helsinki, Finland, May 2016</span>
<div id="Gutmann-2016-05-16">
  <span class="links">
    
    [<a href="https://michaelgutmann.github.io/assets/slides/Gutmann-2016-05-16.pdf" target="_blank">slides</a>]
    
    
    
    [<a href="http://www.hiit.fi/ABCruise/programme.php" target="_blank">url</a>]
    
   
  </span>
    <!-- Hidden abstract block -->
    
    
</div>
  

</li>
<li>


<span class="title">Fast Likelihood-Free Inference via Bayesian Optimization</span>
<span class="periodical"> <i> ABCruise </i> </span>
<span class="periodical">Helsinki, Finland, May 2016</span>
<div id="Gutmann-2016-05-17">
  <span class="links">
    
    [<a href="https://michaelgutmann.github.io/assets/slides/Gutmann-2016-05-17.pdf" target="_blank">slides</a>]
    
    
    [<a class="abstract">abs</a>]
    
    
    [<a href="http://www.hiit.fi/ABCruise/programme.php" target="_blank">url</a>]
    
   
  </span>
    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Statistical models may be specified in terms of stochastic computer program - a simulator - which can generate samples from the model for any configuration of the parameters. While such models support complex data generating mechanisms, the likelihood function is generally incomputable which renders statistical inference difficult. Several likelihoodfree inference methods have been proposed which share the basic idea of identifying the model parameters by finding values for which the discrepancy between simulated and observed data is small. Examples are indirect inference and approximate Bayesian computation. A major obstacle to using these methods is their computational cost. The cost is largely due to the need to repeatedly simulate data sets and the lack of knowledge about how the parameters affect the discrepancy. We propose a strategy which combines probabilistic modeling of the discrepancy with optimization to facilitate likelihood-free inference. The strategy is implemented using Bayesian optimization and is shown to accelerate the inference through a reduction in the number of required simulations by several orders of magnitude.</p>
    </span>
    
    
</div>
  

</li>
<li>


<span class="title">Bayesian Optimization for Likelihood-Free Inference</span>
<span class="periodical"> <i> Gaussian Process and Uncertainty Quantification Summer School </i> </span>
<span class="periodical">Sheffield, UK, Sep 2016</span>
<div id="Gutmann-2016-09-16">
  <span class="links">
    
    [<a href="https://michaelgutmann.github.io/assets/slides/Gutmann-2016-09-16.pdf" target="_blank">slides</a>]
    
    
    
    [<a href="http://gpss.cc/gpuqss16/program" target="_blank">url</a>]
    
   
  </span>
    <!-- Hidden abstract block -->
    
    
</div>
  

</li>
<li>


<span class="title">Bayesian Inference via Classification</span>
<span class="periodical"> <i> ANC Seminar </i> </span>
<span class="periodical">Edinburgh, UK, Oct 2016</span>
<div id="Gutmann-2016-10-04">
  <span class="links">
    
    [<a href="https://michaelgutmann.github.io/assets/slides/Gutmann-2016-10-04.pdf" target="_blank">slides</a>]
    
    
    [<a class="abstract">abs</a>]
    
    
    [<a href="http://www.anc.ed.ac.uk/events/anc-workshop-yuanhua-huang-and-chris-williams-chair-heru-praptono" target="_blank">url</a>]
    
   
  </span>
    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>I present my work on how to infer parameters of complex generative models by solving a series of classification problems.</p>
    </span>
    
    
</div>
  

</li>
<li>


<span class="title">Noise-contrastive estimation of unnormalised statistical models</span>
<span class="periodical"> <i> School of Mathematics, University of Edinburgh </i> </span>
<span class="periodical">Edinburgh, UK, Nov 2016</span>
<div id="Gutmann-2016-11-11">
  <span class="links">
    
    [<a href="https://michaelgutmann.github.io/assets/slides/Gutmann-2016-11-11.pdf" target="_blank">slides</a>]
    
    
    [<a class="abstract">abs</a>]
    
    
    [<a href="http://www.maths.ed.ac.uk/school-of-mathematics" target="_blank">url</a>]
    
   
  </span>
    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Parametric statistical models are often not properly normalised, that is, they do not integrate to unity. While unnormalised models can, in principle, be normalised by dividing them by their integral, the cost of computing the integral is generally prohibitively large. This is an issue because without normalisation, the likelihood function is not available for performing inference.

I present a method called "noise-contrastive estimation" where unnormalised models are estimated by solving a classification problem. I explain some of its properties and applications, and show that it is part of a general estimation framework based on the Bregman divergence.</p>
    </span>
    
    
</div>
  

</li></ol>

  </article>
  
  

  

</div>

      </div>
    </div>

    
<footer>

  <div class="wrapper">
    
        Last updated: 23 September 2017.
    
    Powered by <a href="http://jekyllrb.com/">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> and <a href="https://github.com/inukshuk/jekyll-scholar/">Jekyll-Scholar</a>.

    &copy; Copyright 2017 Michael U. Gutmann.
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="https://michaelgutmann.github.io/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js"></script>
<script src="https://michaelgutmann.github.io/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="https://michaelgutmann.github.io/assets/css/font-awesome.min.css">
<link rel="stylesheet" href="https://michaelgutmann.github.io/assets/css/academicons.min.css">


<!-- Load Mathjax -->
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-XXXXXXXX-X', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
